<!doctype html>
<html>
  <head>
<style>
    #content img {
        width: 200px;
    }
h.solid {border-style: solid;}
a {font-size: 30px;}
h1 {text-align: center;
    color: #158FFA;
  }
  h2 {
    color: #158FFA;
    border-bottom:1px solid #CCC;
    text-align:center;
}
span{
    position:relative;
    top:1px;
    display:inline-block;
    border-bottom:1px solid #AAA;
}
h3 {text-align: center;
    color: #158FFA;
  }
div {text-align: center;}
#heading {
	display: flex;
}
#heading img {
	width: 200px;
margin: 0 auto;
}
pre {counter-reset: line;
    display: inline-block;
    background-color: lightgray;
    background: lightgray; 
    font-size: 15px; 
    padding: 10px; 
    border: 1px solid lightgray; 
    margin: 10px;
    margin-left: 80px;
}
code{
    counter-increment: line;
    
}
code:before{
    content: counter(line);

    
}
</style>
<div id="heading">
    <img src="https://cdn.discordapp.com/attachments/915657987975184445/916373911447408710/data-science-predictions-for-near-future-1024x440.jpeg.optimal.jpeg" class="ribbon"/>
    <div id="title-box">
<h1>Final Project - Data Science for Good</h1>
    <h3>Cora Wagner, Coleman Doherty, Nathaniel Champion<h3>
</div>
    <img src="https://cdn.discordapp.com/attachments/915657987975184445/916373911447408710/data-science-predictions-for-near-future-1024x440.jpeg.optimal.jpeg" class="ribbon"/>
</div>
</head>
<body>
    <h2>Introduction</h2>
      <center><p>The topic we have chosen is the effect of drugs on various statistics within the popular game of Fortnite. The data follows one person throughout a five day period. 
        The affected person is either under the influence of drugs or sober. The statistics we will draw from are the number of eliminations, where they placed, time of day, 
        and the accuracy within their shots fired. Data science will help us clean out the unwanted data that we don’t need. This will include accuracy, revives, headshots, 
        and assists. Using data science we will effectively create data charts to see the effect of drugs on the brain. This data can be used as a proxy to relate real life 
        issues like the effects of alcohol on driving as there are similarities on the physical requirements for safe driving and successful gameplay. Such as: reaction time,
        hand eye coordination, good judgement and decision making and other abilities that can be affected by being high.</p></center>
      <h2>Data Gathering</h2>
      <center><p> The data collection was done by the player who recorded these statistics and his mental state during 80 games over a 5 day period. This data was posted and included
        statistics such as placement in each match, the data and time of the game, how well the player did based on multiple performance metrics and whether the player was under
        the influence of drugs or alcohol. 
          Already created data sets is one option for a computer scientist to use. These data sets usually have clear data in a format that is easy to understand and use. The 
        potential downside is that while this data set may be relevant to the topic it may not be perfectly tailored and have too little or too much information which will need
        to be cleaned.
          Another method of gathering data would be web scraping. This is where a computer scientist writes a code that pulls data from a website and analyzes it to confirm that
        it's relevant to the topic. The code would then need to turn it into a form that is usable to the coder. While this process sounds very simple it can get complicated very
        quickly. Creating code that turns large blocks of data into useful information that can be compared and used to make judgements based on that information can take time and
        effort.</center></p>
	<p>
		Our data gathering step included us finding a .csv file on Kaggle and then reading in the data from the .csv file for our use throughout the code.
		<br>
		This is code in our project that collects the data:
	<pre>
<code>  # Read in a .csv file containing Fortnite statistics</code>  
<code>  file = pd.read_csv('FortniteStatistics.csv')</code> </pre> </p>
      <h2>Data Ethics</h2>
      <center><p> Poorly collected data can have a large effect on the data you are trying to convey. Misleading statistics can have a profound impact on the reader or consumer of the data.
        There are various ways in which data can be misleading. These can include faulty polling, misleading data visualizations, selective bias, flawed correlations, or data 
        fishing. These are just a few ways data can be misleading. Below is one example of a very misleading graph. This graph does a terrible job of displaying information. 
        The first thing wrong with this graph is that it is upside down. This makes the reader think that the number of gun deaths in Florida are increasing when in fact they are
        decreasing. The highest point in the graph is actually the lowest number of gun deaths. This makes completely no sense and confuses the reader. The labeling on this graph
        is also terribly confusing. The ‘Stand Your Ground’ law that was enacted in 2005 doesn’t make too much sense. It makes the reader believe that after the law was enacted
        the number of gun deaths decreased drastically but in reality the number of gun deaths increased. The overall goal of this display is very unclear, and is a perfect 
        example of a misleading data visualization. This line graph can lead people to believe certain things that are untrue.</p></center>
      <center> <img src="https://cdn.discordapp.com/attachments/915657987975184445/915658642840256602/h5MSdPM97fm55kTk4kk4P7.jpg" alt="Gun Deaths in Florida Graph" width="400" height="500"></center>
      <h2>Munging, Wrangling, and Data Cleaning</h2>
      <center><p> Data Cleaning is a method that is used to take raw data and transform it into something useful. Changing the format of the data may be necessary to create graphs or 
        perform calculations to illustrate or support the conclusion a computer scientist is trying to make about a particular topic. Two ways of doing this are Munging and 
        Wrangling.</p></center>
      <h2>What is Munging?</h2>
      <center><p> This term is used to describe the filtering or transforming of raw data into a more usable form. This is usually done in steps. For example if the data a computer
        scientist gathered looked like this.</p></center>
      <br>
      <center><p> “The school bus goes to West High School @ 5:40 AM every weekday.”
             <br>
                  “The school bus goes to West High School @ 3:40 PM every weekday.”
             <br>
                  “The school bus goes to East Middle School @ 6:15 am every weekday.”</p></center>
      <br>
      <center><p> If the computer scientist wanted to know what school the bus went to at what time then step 1 may be to make all the text lower case. Step 2 may be to remove the
        parts of the string after ‘am’ or ‘pm’ and the beginning of the string ‘The school bus goes to’. Step 3 would then be to split the school from the time and change
        the time to military. The cleaned data may look more like this:</p></center>
      <br>
      <center><p> “West High School”, “0540”
                  <br>
                  “West High School”, “1540”
                  <br>
                  “East Middle School”, “0615”</p></center>
      <p>
	      Our first step in the data cleaning process was to create a data frame that contained the Time, Sobriety, Placement, Eliminations, and Accuracy columns from the .csv file. 
	      This allowed for us to ignore all the rest of the columns within the .csv file. At this step, we also created 2 separate data frames correlating to sober and high. 
	      We did this so that we could separate the data for the player while he was sober, and then for when he was high. 
	      We were able to provide two lines of best fit since we separated the data for sober and high from the initially created data frame.
	      <br><br>
	      This is our first step in cleaning the data into a more useable form:
	      	<pre> 
<code>  # Clean the data by creating a data frame that contains the specific data we want</code>  
<code>  #       (Time, Sobriety, Placement, Eliminations, and Accuracy)</code>  
<code>  data = {'Time': file['Time of Day'].tolist(), 'Sobriety': file['Mental State'].tolist(), 'Placement': file['Placed'].tolist(),</code>  
<code>          'Eliminations': file['Eliminations'].tolist(), 'Accuracy': file['Accuracy'].tolist()}</code>  
<code>  df = pd.DataFrame(data, columns=['Time', 'Sobriety', 'Placement', 'Eliminations', 'Accuracy'])</code>  
<code>  </code>  
<code>  # Separates the data based on Sobriety in order to create 2 lines (sober and high) for each</code>  
<code>  #       linear regression graph</code>  
<code>  soberDF = df.loc[df.Sobriety == "sober"]</code>  
<code>  highDF = df.loc[df.Sobriety == "high"]</code>  </pre> </p>
	      <p>
		      Our second step in data cleaning was to create individual lists of the data to be used in creating the graphs. 
		      We ran into an error where our code to create the graph would not take in data straight from the data frame. 
		      Creating the individual lists for the data we needed to graph was our way of getting around this error. 
		      We also created variables for easy title and label creation on the graphs.
		      <br><br>
		      Our second step in the cleaning of data is:
	     	<pre> 
<code>  # Variables for graph labels</code>  
<code>  p = "Placement"</code>  
<code>  e = "Eliminations"</code>  
<code>  a = "Accuracy (%)"</code>  
<code>  </code>  
<code>  # Lists from data frame data in order to use when creating graphs</code>  
<code>  sTime = soberDF['Time'].tolist()</code>  
<code>  hTime = highDF['Time'].tolist()</code>  
<code>  sSob = soberDF['Sobriety'].tolist()</code>  
<code>  hSob = highDF['Sobriety'].tolist()</code>  
<code>  sPlace = soberDF['Placement'].tolist()</code>  
<code>  hPlace = highDF['Placement'].tolist()</code>  
<code>  sElm = soberDF['Eliminations'].tolist()</code>  
<code>  hElm = highDF['Eliminations'].tolist()</code>  
<code>  sAcc = soberDF['Accuracy'].tolist()</code>  
<code>  hAcc = highDF['Accuracy'].tolist()</code> </pre> </p>
	      <p>
		      Our third step in data cleaning was to remove all characters after the : in the Time data for both the sober and high data. 
		      We needed to do this in order to graph the time since the data needs to be an integer and not a string. 
		      In this step we also set 12 PM equal to 0, since 12 PM would be graphed after 11 PM and display the data incorrectly. 
		      We were able to make this change since all the time data took place in the PM.
		      <br><br>
		      The third step for our cleaning process:
		<pre> 
<code>  # Removes the characters after the : and converts the string to an int</code>  
<code>  #       i.e. 10:00 PM becomes 10</code>  
<code>  # It also converts 12 to 0 so that the data for 12 pm comes before the data</code>  
<code>  #       for 1 pm</code>  
<code>  intTimeSob = []</code>  
<code>  for i in sTime:</code>  
<code>      s = i.split(":", 1)</code>  
<code>      r = int(s[0])</code>  
<code>      if r == 12:</code>  
<code>          r = 0</code>  
<code>      intTimeSob.append(r)</code>  
<code>  </code>  
<code>  intTimeHig = []</code>  
<code>  for i in hTime:</code>  
<code>      s = i.split(":", 1)</code>  
<code>      r = int(s[0])</code>  
<code>      if r == 12:</code>  
<code>          r = 0</code>  
<code>      intTimeHig.append(r)</code> </pre> </p>
	      <p>
		      Our final step in data cleaning was to remove the % in the Accuracy data. 
		      We needed to do this for the same reason we removed characters from the Time data. 
		      The data would not work in a graph if it was not an integer.
		      <br><br>
		      Our final step in cleaning our data into an ideal form for analysis is:
		<pre> 
<code>  # Removes % sign from the Accuracy data and converts the string to an int</code>  
<code>  #       i.e. 30% becomes 30</code>  
<code>  intAccSob = []</code>  
<code>  for j in sAcc:</code>  
<code>      u = j.split("%",1)</code>  
<code>      v = int(u[0])</code>  
<code>      intAccSob.append(v)</code>  
<code>  </code>  
<code>  intAccHig = []</code>  
<code>  for j in hAcc:</code>  
<code>      u = j.split("%",1)</code>  
<code>      v = int(u[0])</code>  
<code>      intAccHig.append(v)</code> </pre> </p>
	      
      <h2>What is Wrangling?</h2>
      <center><p>This term is used to describe changing raw data that can be very complicated or includes lots of unnecessary data into something more easily understandable and
        simple to use. For example if the data gathered was a table that included 15 column metrics about a list of schools but the computer scientist only needs 2 of those
        metrics as those are the only ones relevant to his project. Then reducing that table to a smaller more manageable form would by a type of wrangling. </p></center>
      <h2>Analysis</h2>
      <center><p>To analyze our data we chose to use the regression algorithm rather than one of the classification algorithms. The reason for not using a classification 
	      algorithm is because with our particular data set we are not using our current data to predict future data. Both the multinomial and gaussian algorithms predict
	      future data points. In our case we do not care about future statistics, so we chose to use the regression algorithm. We chose to use the number of eliminations,
	      where they placed, time of day, and the accuracy within their shots fired. The independent variable that we are not changing is the time of day. This will be 
	      consistent when comparing it to the dependent variables which are the number of eliminations, placement, and accuracy. We chose these variables because they were
	      the closest approximations when you compare it to real life drinking and driving. Each one of these variables relate to reaction time and hand eye coordination,
	      both of which are important to driving.</p></center>
      <p>
	      The following code produces our graphs which we will use to support our assertion that getting high has a negative impact on hand eye coordination and 
	      reaction time:
	    	<pre> 
<code>  # Function that creates the graphs for each set of data given as parameters</code>  
<code>  def graph(x_sober, x_high, y_sober, y_high, x_name):</code>  
<code>      # Plot data points</code>  
<code>      plt.scatter(x_sober, y_sober) # sober: red</code>  
<code>      plt.scatter(x_high, y_high) # high: blue</code>  
<code>  </code>  
<code>      # Plot line of best fit</code>  
<code>      x = np.array(x_sober)</code>  
<code>      y = np.array(y_sober)</code>  
<code>      m, b = np.polyfit(x, y, 1)</code>  
<code>  </code>  
<code>      plt.plot(x, y, 'o')</code>  
<code>      plt.plot(x, m*x + b, 'blue', label = "Sober")</code>  
<code>  </code>  
<code>      x2 = np.array(x_high)</code>  
<code>      y2 = np.array(y_high)</code>  
<code>      n, c = np.polyfit(x2, y2, 1)</code>  
<code>  </code>  
<code>      plt.plot(x2, y2, 'o')</code>  
<code>      plt.plot(x2, n*x2 + c, 'orange', label = "High")</code>  
<code>  </code>  
<code>      # Add title and axis labels</code>  
<code>      plt.title(x_name + " Based on Sobriety")</code>  
<code>      plt.xlabel(x_name)</code>  
<code>      plt.ylabel("Time (PM): 12 PM is shown as 0 to place it below 1 PM")</code>  
<code>      plt.yticks(np.arange(0,12,1))</code>  
<code>  </code>  
<code>      plt.legend()</code>  
<code>      plt.savefig("" + x_name + ".png")</code>  
<code>      plt.show()</code>  
<code>  </code>  
<code>  # Function calls for the function creating the individual graphs</code>  
<code>  #   graph(x_sober, x_high, y_sober, y_high, x_name)</code>  
<code>  graph(sPlace, hPlace, intTimeSob, intTimeHig, p)</code>  
<code>  graph(sElm, hElm, intTimeSob, intTimeHig, e)</code>  
<code>  graph(intAccSob, intAccHig, intTimeSob, intTimeHig, a)</code> </pre> </p>
<p> Test Image </p>
![Accuracy Graph](https://github.com/ColeDoh/FinalProject/blob/main/Accuracy%20(%25).png)
</body>
</html>     
